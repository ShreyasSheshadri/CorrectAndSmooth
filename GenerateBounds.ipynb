{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9cf5a15",
   "metadata": {},
   "source": [
    "# Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65f9ec",
   "metadata": {},
   "source": [
    "## Input \n",
    "### A - numpy array, Adjacency Matrix\n",
    "### X - numpy array, Node Features\n",
    "### train_ids - numpy array, Train Node IDs. Make sure that Train ids range [0, V-1]\n",
    "### nrounds_smooth - No of rounds of Smoothing. Use nrounds_smooth = 0 to use only raw node features. \n",
    "### L - No. of Layers of MLP. If Linear classifier use L = 1\n",
    "### K - No of Classes. K = 2 for Binary classification\n",
    "### W - list of parameters (numpy 2D arrays). Each element of the list is parameter of a layer of MLP. These parameters needn't be ordered. Just pass each layer parameter as an element of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae7af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d0c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bounds(N, X, distX, train_ids, L, K, W):\n",
    "    \n",
    "    # Define constants in bounds\n",
    "    ## Lipchitz parameter c - Not sure how to measure. Setting it to 1/max(em). Look at eq following eq.14 in the paper\n",
    "    c = 1/max(distX.keys())\n",
    "    ## N_o = No of Train nodes \n",
    "    N0 = train_ids.shape[0]\n",
    "    ## alpha - There exists such a value! See Assumption 3 and discussion after Equation 15, \n",
    "    ## it governs probability of undesirable event. So should be set to high value i.e., 1/4\n",
    "    alpha = 0.25 - 1e-6\n",
    "    ## delta - Confidence, setting it 0.9\n",
    "    delta = 0.9\n",
    "    ## gamma - Margin setting it low value 1e-4\n",
    "    gamma = 1e-4\n",
    "    ## b - Apparently from a spectral norm inequality. I couldn't locate it in the reference. \n",
    "    ## They didn't even point the equation out!!\n",
    "    b = 1\n",
    "    ## C - Upper bound on Frenobius Norm of Wieghts \"W_Fn\". Setting it to ceil() of the max Frenobius norm, W_Fn\n",
    "    W_Fn = np.sum([np.sum(np.square(w)) for w in W])**0.5\n",
    "    C = np.ceil(W_Fn)\n",
    "    ## Norm of the Smoothed Features\n",
    "    B = np.linalg.norm(X, axis=1)\n",
    "    B0 = np.max(B[train_ids])\n",
    "    \n",
    "    def compute_upper_bound(vi, dxi):\n",
    "        ub = c * K * dxi\n",
    "        ub += ((W_Fn*b) * (dxi**2) /(N0**alpha*(gamma/8)**2))\n",
    "        ub += N0**(2*alpha-1)\n",
    "        xb = (L*C*2*B[vi])/(delta*gamma)\n",
    "        ub += N0**(-2*alpha) * np.log(xb + 1e-6)\n",
    "        return ub\n",
    "    \n",
    "    gen_bounds = {}\n",
    "    test_ids = np.setdiff1d(np.arange(N), train_ids)\n",
    "    for vi in test_ids:\n",
    "        gen_bounds[vi] = compute_upper_bound(vi, distX[vi])\n",
    "    maxCS = max([gen_bounds[x] for x in gen_bounds])\n",
    "    gen_bounds = {x: gen_bounds[x]/maxCS for x in gen_bounds}\n",
    "    return gen_bounds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c9f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c69bbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch[07:24:00] /opt/dgl/src/runtime/tensordispatch.cc:\n",
      "43: TensorDispatcher: dlopen failed: /home/shreyshs/anaconda3/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c121e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from outcome_correlation import process_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c7584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a6ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e72740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6598a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_bounds(dataset_name, model_name):\n",
    "    \n",
    "    dataset = PygNodePropPredDataset(name='ogbn-{}'.format(dataset_name))\n",
    "    data = dataset[0]\n",
    "    adj, D_isqrt = process_adj(data) # not really required\n",
    "    adj = adj.to_symmetric()\n",
    "    split_idx = dataset.get_idx_split()\n",
    "    \n",
    "    #train_ids = np.concatenate([split_idx ['train'], split_idx['valid']])\n",
    "    train_ids = split_idx ['train']\n",
    "    X = data.x\n",
    "    embeddings = None \n",
    "    if dataset_name == 'products':\n",
    "        embeddings = torch.load('embeddings/spectral{}.pt'.format(dataset_name))\n",
    "    else:\n",
    "        embeddings = torch.load('embeddings/diffusion{}.pt'.format(dataset_name))\n",
    "    if dataset_name == 'arxiv':\n",
    "        embeddings = torch.cat([embeddings, torch.load('embeddings/spectral{}.pt'.format(dataset_name))], dim=-1)\n",
    "    if model_name == 'linear' or model_name == 'mlp':\n",
    "        X = torch.cat([X, embeddings], dim=-1)\n",
    "    X = X.numpy()\n",
    "    K = dataset.num_classes\n",
    "    N = data.num_nodes\n",
    "    \n",
    "    def get_ann_distance(Y):\n",
    "        p = hnswlib.Index(space = 'l2', dim = Y.shape[1])\n",
    "        p.init_index(max_elements = Y.shape[0]+1, ef_construction = int(0.05*Y.shape[0]), M = 256)\n",
    "        p.add_items(Y[train_ids], train_ids.numpy())\n",
    "        labels, distances = p.knn_query(Y, k = 5)\n",
    "        agg_distance = {}\n",
    "        for i in range(N):\n",
    "            agg_distance[i] = distances[i, 0]\n",
    "        return agg_distance\n",
    "    \n",
    "    # Compute distance to the Train nodes\n",
    "    def get_agg_distance(Y):\n",
    "        agg_distance = {}\n",
    "        for i in range(A.shape[0]):\n",
    "            agg_distance[i] = float('inf')\n",
    "            for j in train_ids:\n",
    "                agg_distance[i] = min(agg_distance[i],\n",
    "                                      np.linalg.norm(Y[i] - Y[j]))\n",
    "        return agg_distance\n",
    "    \n",
    "    distX = None\n",
    "    if dataset_name == 'cora' or dataset_name == 'citeseer' or dataset_name == 'pubmed':\n",
    "        distX = get_agg_distance(X)\n",
    "    else:\n",
    "        distX = get_ann_distance(X)\n",
    "    \n",
    "    save_path = 'generalization_bounds/{}-{}'.format(dataset_name, model_name)\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    \n",
    "    for runs in range(10):\n",
    "    \n",
    "        model_weights = torch.load('models/{}_{}/model-{}.tar'.format(dataset_name, model_name, runs))['model_state_dict']\n",
    "        \n",
    "        a = None \n",
    "        b = None\n",
    "        W = []\n",
    "        \n",
    "        if model_name == 'mlp':\n",
    "            for i in range(3):\n",
    "                a = model_weights['lins.{}.weight'.format(i)].numpy()\n",
    "                b = model_weights['lins.{}.bias'.format(i)].numpy()\n",
    "                b = b.reshape((b.shape[0], 1))\n",
    "                W.append(np.hstack((a, b)))\n",
    "        else:\n",
    "            a = model_weights['lin.weight'].numpy()\n",
    "            b = model_weights['lin.bias'].numpy()\n",
    "            b = b.reshape((b.shape[0], 1))\n",
    "            W.append(np.hstack((a, b)))\n",
    "\n",
    "        L = len(W)\n",
    "        gen_bounds = compute_bounds(N, X, distX, train_ids, L, K, W)\n",
    "        y_score = torch.load('models/{}_{}/{}.pt'.format(dataset_name, model_name, runs), map_location='cpu')\n",
    "        yhat = y_score.argmax(dim=-1, keepdim=True).numpy()\n",
    "        \n",
    "        E_matrix = np.zeros((N, K))\n",
    "        for i in gen_bounds:\n",
    "            E_matrix[i] = E_matrix[i] + gen_bounds[i]\n",
    "        E_matrix = torch.tensor(E_matrix, dtype=torch.float32)\n",
    "        torch.save(E_matrix, '{}/fixed-{}.th'.format(save_path, runs))\n",
    "        \n",
    "        E_matrix = np.zeros((N, K))\n",
    "        for i in gen_bounds:\n",
    "            E_matrix[i] = E_matrix[i] + (1 - gen_bounds[i])/K\n",
    "            pred_indx = int(yhat[i])\n",
    "            E_matrix[i, pred_indx] = gen_bounds[i]\n",
    "        E_matrix = torch.tensor(E_matrix, dtype=torch.float32)\n",
    "        torch.save(E_matrix, '{}/spread-{}.th'.format(save_path, runs))\n",
    "        \n",
    "        E_matrix = np.zeros((N, K))\n",
    "        for i in gen_bounds:\n",
    "            rc = np.random.random(K)\n",
    "            rc /= rc.sum()\n",
    "            E_matrix[i] = E_matrix[i] + rc\n",
    "        E_matrix = torch.tensor(E_matrix, dtype=torch.float32)\n",
    "        torch.save(E_matrix, '{}/random-{}.th'.format(save_path, runs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab6cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('cora', 'plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b2386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('cora', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b158e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('cora', 'mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7619ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('citeseer', 'plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f2ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('citeseer', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e89059",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('citeseer', 'mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8673973",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('pubmed', 'plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3381fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('pubmed', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f37f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('pubmed', 'mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7e24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('arxiv', 'plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1fdadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('arxiv', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd6635eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('arxiv', 'mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5a94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('products', 'plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760eb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('products', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc1c4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_bounds('products', 'mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5de3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
